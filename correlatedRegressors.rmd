---
output: md_document
---

##Searching for significance in correlated variables

Business problem: A manager suspects that a given variable $V_2$ is significantly predictive of a $Y$, but $V_2$ is extremely correlated with $V_1$, a variable already incorporated into your company's simple linear model. 

The manager wants the answer *now*: is $V_2$ important or not?

Some things to consider:


1. Is it informative/safe to look at linear model coeffecients in a regression of $V_1$ and $V_2$ on $Y$? 

2. What other strategies are worth considering? 

3. Does running a linear model on the residuals of a first stage model help?

4. How can we measure results in terms of false postives vs. false negatives? 


------------

##Setup

Let's use the following setup to test
$[V_{1},V_{2}] \sim N(\mu,\Sigma)$

With $cov(V_1,V_2)=.9$, $var(V_1) = var(V_2) = 1$

Let $V_3 \sim N(V_2,.5)$

$Y \sim N(V_1 + V_2,1)$ 


###Approach:

We test both under the null hypothesis that $V_2$ contains no additional information ($V_{2 null}$) and the alternative hypothesis in which $V2$ does contain information ($V_{2 alt}$)

```{r,createSampleData,message=FALSE}
library(MASS)
library(magrittr)
library(dplyr)
set.seed(5000)

createSigma <- function(corr=.9) {
Sigma <- diag(4) 
Sigma[1,2] = Sigma[2,1] = .9
return(Sigma)
}

simulateData <- function(V2coef=1,corr=.9,n=20) {
  mvrnorm(n = n, mu=rep(0,4), createSigma(corr), tol = 1e-6, empirical = FALSE, EISPACK = FALSE) %>% 
  as.data.frame %>%
  rename(V2_alt = V2, e1 = V3, e2 = V4) %>%
  transform(Y=  V1 + V2_alt + e1,
            V2_null = V1 + e2) %>% return
}

sampleData <- simulateData()
with(sampleData,
     plot(Y,V1))
```

Inspecting the linear models, you'd probably be surprised to see

```{r, linearModels}
simulation <- list(data = sampleData)
simulation$results <- with(simulation$data, list(
  fullModel = lm(Y ~ V1 + V2_alt +V2_null),
  v1Model = lm(Y ~ V1),
  v2_alt_Model = lm(Y ~ V1 + V2_alt),
  v2_null_Model = lm(Y ~ V1 + V2_null)))

#to do lapply(simulation$results, function(x) {assign(names(x)) = x})
attach(simulation$results) #just for this demo
summary(fullModel)$coef
```
So, the new variable $V2$ is significant but your old variable $V1$ no longer is...
My first thought would be to use ANOVA:


```{r} 
anova(fullModel)
anova(v1Model,v2_alt_Model)
```

Note that Sum of Squares are the same as the first comparison in anova(fullModel), but degrees of freedom are different.
That's why anova(model1,model2) is best. 

```{r}
anova(v1Model,v2_null_Model)
```

Someone I talked to suggested first regressing Y on V1, and then the residuals on V2.
```{r}
v2_alt_ResidModel <- lm(resid(v1Model) ~ sampleData$V2_alt - 1)
summary(v2_alt_ResidModel)$coef

v2_null_ResidModel <- lm(resid(v1Model) ~ sampleData$V2_null -1 )
summary(v2_null_ResidModel)$coef
```
I wouldn't recommend this approach.



##Followup Questions!

1. looking at linear model coeffecients is safe/not safe (pick one)

2. ANOVA is better/not better

3. We could compare procedures by using what metrics?


##Simulations

It would be better to draw conclusions from more than one observation!
```{r}
#todo!

singleSimulation <- function(corr,true_effect,n_obs) {
  #input:  
  #output: a list with two linear models
  data <- simulateData(V2coef = true_effect,corr = cor,n=n_obs)
  res <- list()
  res$model_null <- lm(Y~V1 + V2_null,data=data)
  res$model_alt <- lm(Y~V1 + V2_alt,data=data)
  return(res)
}

# testWithPValue <- function(linear_model) {
#   #input: a single linear model)
#   #output: p-value associated with ..? 
#   (summary(linear_model)$coef[,colnames(summary(linear_model)$coef)=="Pr(>|t|)"]) %>%
#     return
# }

returnCoeffecients <- function(linear_model) {
  #input: a single linear model
  #output: two coeffecients
  linear_model$coef[3] %>% #[c("V2_alt","V2_null")] %>% // only return one?? 
    return
}

returnPValue <- function(linear_model) {
  temp <- linear_model %>% summary %>% `$`(coef) %>% `[`(3,4)
  #print(linear_model)
  return(temp)
  
  
}


testMethod <- function(significantMethod=returnCoeffecients, corr=seq(0,.95,by=.05),true_effect=(1:10), n_obs=20,n_sim=10) {
  #input: significantMethod function
  #corr: numeric vector correlation of the two variables
  #true_effect: numeric vector of true effects to measure.
  #for each combination of parameters (creates a matrix of all possible parameters)
  #and the false positive result
  true_effect <- c(true_effect) #test type II error as well! 
  sim_results <- expand.grid(corr=corr,true_effect=true_effect,n_obs=n_obs,n_sim=1:n_sim)
  sim_results[paste0("sim_",1:n_sim)] <- NA
  #now, you can run these simulations however you want
  #generate data
  apply(sim_results[c("corr","true_effect","n_obs","n_sim")],1,
        function(x) {
          c(
            x["corr"],
            x["true_effect"],
            x["n_obs"],
            x["n_sim"],
            singleSimulation(corr=x["corr"],true_effect=x["true_effect"] , n_obs = x["n_obs"]) %>% #returns list of two
            sapply(.,significantMethod)
            ) %>%
          #pull coef of interest from both regressions
          return
        }
      ) %>% 
    t %>%
    as.data.frame %>%
    return
}

res<-testMethod(significantMethod=returnPValue)
head(res)
save(res,file="res.RData")

euclideanDistance <- function(x,y) {
  return(sqrt(sum((x-y)^2)))
}

binaryClassification <- function(model_null,model_alt) {  
  (model_null < .05) + (model_alt > .05) %>%
  return
  }

# create a summary
createHeatMap <- function(df,lossFunction=binaryClassification,only_n_obs=20) {
  library(gplots)
  library(tidyr)
  # input: testMethod-result dataframe
  # output: summary data frame
  # side effect: print out a heatmap with loss function
  names(df) <- c("corr","true_effect","n_obs","n_sim","model_null","model_alt")
  temp <- 
  df %>% 
    mutate(true_null=0) %>%
    mutate(loss = binaryClassification(model_null,model_alt)) %>%
     group_by(corr,true_effect,n_obs) %>%
    mutate(true_null = 0) %>%
    summarise(meanLoss = sum(loss)/n())
  print(head(temp))
  
#   toPlot <- temp %>% 
#     select(corr,true_effect,meanLoss) %>%
#     spread(true_effect,meanLoss) %>%
#   row.labels <- toPlot[,1] #corr values
#   toPlot %>% as.matrix %>%
#     heatmap.2(.,Rowv=NULL,Colv=NULL,dendogram="none",trace="none",
#               key=FALSE,labCol=row.labels,cexCol=1)
  return(temp)

}

sim_res <- createHeatMap(res,lossFunction=binaryClassification)
head(sim_res)
save(sim_res,file="heatmap.RData")

```

```{r}

# toPlot <- sim_res %>% 
#   dplyr::select(corr,true_effect,meanLoss) %>%
#   tidyr::spread(corr,meanLoss) %>%
#   data.matrix 
# 
# row.names(toPlot) <- toPlot[,1]
# 
# heatmap(toPlot[,2:20],Rowv=NA,Colv=NA,col=cm.colors(256),scale="column",margins=c(5,10))
#   heatmap.2(Rowv = FALSE,Colv=FALSE,dendrogram="none")
```